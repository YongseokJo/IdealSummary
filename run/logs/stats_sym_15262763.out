Running on host: gpua045.delta.ncsa.illinois.edu
Starting at: Sat Jan  3 18:19:41 CST 2026
CUDA visible devices: 0
Python 3.12.1
/u/gkerex/pyenv/torch/bin/python
job is starting on gpua045.delta.ncsa.illinois.edu
Running: python -u ../src/train_stats_sym.py --h5-path ../data/camels_LH.hdf5 --n-generations 20 --n-weight-epochs 5 --n-transforms 4 --top-k 16 --batch-size 64 --normalize-input log_std --normalize-output minmax --wandb --wandb-project stats_sym --save-model --save-plots
Using device: cuda

Loading data...
Dataset size: 1000
Target params: ['Omega_m', 'sigma_8', 'A_SN1', 'A_AGN1', 'A_SN2', 'A_AGN2']
Split sizes -> train: 800, val: 100, test: 100
Computing normalization statistics...
Input features: 1, Output dim: 6
WandB initialized: woven-sponge-1

Creating model...
Model parameters: 4,071
Summary features: 96
Statistics per transform: 24

Starting training...

============================================================
Training Simplified Set-DSR
============================================================
Population size: 50
Generations: 20
Transforms: 4
Summary features: 96
Top-K: 16
============================================================

Gen   0 | Best: -1000000.0000 | Mean: -1000000.0000
  g0: m
  g1: abs(m)
  g2: (m add m)
Gen   5 | Best: -1000000.0000 | Mean: -1000000.0000
  g0: x_0
  g1: ((m mul x_0) sub abs(identity(x_0)))
  g2: sin(m)
Gen  10 | Best: -1000000.0000 | Mean: -1000000.0000
  g0: x_0
  g1: ((m mul x_0) sub abs(identity(x_0)))
  g2: sin(m)
  â†’ Retraining weights and head...
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mwoven-sponge-1[0m at: [34m[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20260103_181953-0n81a7js/logs[0m
